\newpage
\chapter{Experiments}
\label{sec:experiments}

In this section, we will use both quantitative as well as qualitative experiments to test our methods, compare them and draw conclusions about their performance and their properties. 

\section{Datasets}
\label{subsec:dataset}
\noindent
We used three datasets in order to test our methods. The first one is a Synthetic dataset which we created to verify, on one hand, that the models did in fact work in controlled and regular conditions and, on the other, to carry out simple qualitative experiments with which to verify certain assumptions. Some of these images we created can be seen in figure \ref{fig:database_synthetic}.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/gaussian_image_1__.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/gaussian_image_11.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/gaussian_image_9.png}\\[0.2em]
	
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/gaussian_image_19.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/gaussian_image_22.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/gaussian_image_17.png}\\[0.2em]
	\caption{Images from the Synthetic dataset}
	\label{fig:database_synthetic}
\end{figure}




 The other two datasets are a subsets of two existing datasets of real images. The first one is a subset of 40 images from the Single Object Database (AlpertGBB07)~\cite{AlpertGBB07}. This dataset is characterized by having well defined backgrounds from the foreground. We discarded those images that we did not consider fit the criteria for which cage active contours were created, that is, images with single connected objects with no holes and visually distinct from the background. In figure \ref{fig:database_sod} shows images from the original dataset, the image of a chain is an example of an object we removed from the dataset because it does not meet the criteria of the CAC of having no relevant holes. 
 This dataset from the Weizmann Institute of Science provides human-segmentations as ground truth. It is worth noting, however, that the ground truth segmentations are done so manually and independently by three individuals, thus result in contradictions at times. We have chosen the one we have thought best met the CAC's criteria.
 
 \begin{figure}[h!]
 	\centering
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/chain98.png}\hspace{0.025\textwidth}%
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/beltaine_4_bg_050502.png}\hspace{0.025\textwidth}%
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/bream_in_basin.png}\\[0.2em]
 	
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/broom07.png}\hspace{0.025\textwidth}%
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/pic109250805856.png}\hspace{0.025\textwidth}%
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/b14pavel013.png}\\[0.2em]
 	\caption{Images from the Single Object Database (AlpertGBB07)}
 	\label{fig:database_sod}
 \end{figure}
 
 The second dataset is the Berkeley Segmentation Dataset and Benchmark (BSDS300)\cite{MartinFTM01}. This dataset consisting of 300 real images which are much more complex than the Single Object Dataset since they are chosen in order to evaluate image segmentation in general and not object segmentation. Nevertheless we have chosen a subset of 20 images from this dataset that was used in~\cite{grabCutDS} and whose ground truth they provide for object segmentation. In figure \ref{fig:database_bsds300}, some images from this sub-dataset are shown so that its complexity can be appreciated.

 \begin{figure}[h!]
 	\centering
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/153093.png}\hspace{0.025\textwidth}%
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/21077.png}\hspace{0.025\textwidth}%
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/271008.png}\\[0.2em]
 	
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/181079.png}\hspace{0.025\textwidth}%
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/189080.png}\hspace{0.025\textwidth}%
 	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/real_images/304074.png}\\[0.2em]
 	\caption{Images from the BSDS300 subset}
 	\label{fig:database_bsds300}
 \end{figure}
 

\vspace{1cm}
\section{Validation}
\label{subsec:validation}
\noindent

\subsection{Evaluation Measures}
The best measure to evaluate a segmentation depends largely on the consequences that any error in the segmentation might have. In practice this depends completely on the application. In medical image, for example, the segmentation of the a brain lesion can serve a variety of purposes. When monitoring size, an error measure that is sensitive to area would be more appropriate. On the other hand, if when treating a tumor, shape fidelity of the segmentation is key in order to know where to apply radiation. In this case, having a measure that is more focused on outline would avoid targeting healthy tissue or not targeting a malicious one~\cite{1717643}.

Overlap ratio measures usually range from 0 to 1, from least to most congruent. They are sensitive to misplacement of the segmentation label, so in general they do not capture shape fidelity. Among these measures, the most popular are the S\o rensen-Dice similarity index and the Jaccard overlap ratio. The Jaccard Index is numerically more sensitive to mismatch when there is reasonably strong overlap. Dice values are higher for the same pair of segmentations~\cite{1717643}.
%(Rohlfing et al. 2004, linked below)

Let X be the segmentation region and Y the ground truth segmentation region. 
The Jaccard index is expressed as 
\begin{equation}\label{eq:jaccard_coeff}
	c_{Jaccard}(X,Y)= \frac{\vert X \cap Y \vert}{\vert X \cup  Y \vert} 
\end{equation}
The S\o rensen-Dice coefficient is

\begin{equation}\label{eq:sorensen-dice_coeff}
	c_{Sorensen-Dice}(X,Y)= 2\frac{\vert X \cap Y \vert}{\vert X \vert + \vert Y \vert} 
\end{equation}

Another interesting metric is the Hausdorff distance~\cite{evaluation_metrics}. The idea of this metric is that a segmentation is only as good as its worst good point. It is expressed as follows:

\begin{equation}\label{eq:haussdorff_coeff}
d_{H}(X,Y)= max(\vec{d_H}(X,Y),\vec{d_H}(Y,X))
\end{equation}
where the directed haussdorf distance $\vec{d_H}$ is:
\begin{equation}\label{eq:directed_haussdorff_coeff}
\vec{d}(X,Y) = \max\limits_{x\in X}\min\limits_{y\in Y}\norm{x-y}
\end{equation}
This last one is used when very high precision and shape fidelity is desired. Its drawbacks include high computational cost, because of the huge number of comparisons it requires, and a very disproportionate penalizations for even a single point~\cite{Huttenlocher:1993:CIU:628305.628513}.

We have chosen to evaluated the S\o rensen-Dice coefficient because of its simplicity and use in object image segmentation. 

Another form of evaluation which we will use is visual criteria. This can serve in qualitative experiments to evaluate for example whether a segmentation has been carried out successfully or not. 

\subsection{Model Validation}
\label{subsec:model_validation}

Cage Active contours are adaptive methods with no learning. By adaptive we mean that through a few basic rules, imposed in this case on the Energy and the cage, a certain of intelligence emerges. The more elaborated these set of rules are, the more complex objects it will be able to segment. From simple rules, a more abstract and complex behavior emerges. Furthermore, CAC have no learning since its performance does not improve the more objects it segments. 

Usually in model evaluation there are two main points that we want to know:
\begin{itemize}
	\item The overall score of a method
	\item The best model for that method
\end{itemize}

In our case, the method corresponds to an Energy Function on CAC while a model is a set of parameters. 
A model, in the case where there is no learning, is evaluated as the mean score result throughout the whole dataset. The best method would then be that which best scores in a dataset.

To evaluate a \textit{method}  without over-fitting, we use k-fold cross-validation. This is an iterative process in which a k-th part (fold) of the dataset is taken, different models are evaluated on it such that the model with the best score is considered to be \textit{validated}, and goes on to be evaluated using the rest of the dataset. This is repeated k times with k different parts for model validation. At the end, the score in each fold is averaged thus giving the final score of the method.

\section{Qualitative Experiments}
\label{subsec:qualitative_experiments}
Using the synthetic dataset we have challenge and compared the different energy functions we have created. We wanted to see whether they would succeed in the segmentation of objects they were created to segment. 
In oder to check various hypotheses of our proposed method, we decided to compare in a very controlled manner, the previous energies in CAC with our contributions.

It is important to stress the fact that qualitative experiments neither prove anything, nor are they conclusive. What they can do is disprove and help shed light on certain phenomena.

\subsection{Parameters}

The parameters used in this experiments are the ones seen in table \ref{table:parameters} and a list of their values which we have tested for real images is provided in the Values column.

\begin{table}[h!]
	\centering
	\begin{tabular}{|l|l|l|}
		\hline
		\textbf{Parameters} & \textbf{Symbol}&\textbf{Values}   \\ \hline
		Number of Control points& $N$& 16, 20, 24 \\ \hline
		Cage-contour ratio & $r$ & 1.05, 1.1 \\ \hline
		Sigma & $\sigma$ & 0.25, 0.5, 0.7\\ \hline
		Substitute value~\tablefootnote{This parameter is specific to the Mixture Gaussian Energy}  & $\varepsilon$ & $\exp^{-100}$, $\exp^{-200}$, $\exp^{-300}$\\ \hline
	\end{tabular}
	\caption{List of values chosen for each parameter.}
	\label{table:parameters}
\end{table}

The first parameter is the number of points the initial cage has. In \cite{ipcac2015}, the authors test the influence of this parameter in different shapes. They conclude that the more points the better the segmentation in complex objects. We argue that it must be correlated with the maximum number of curvature changes in the curve and we leave this as a possible field of study in section \ref{sec:conclusions}.

The cage-contour is explained in detail in section \ref{sec:properties_parametrization}. This is in relation to the distance between the initial cage and the contour. As we have discussed in section \ref{sec:mean_value_coordinates}, this ratio is correlated with the degree of influence of the contour with respect to the cage. The bigger the ratio, the lower the cage's influence on the contour (see image \ref{fig:different_ratios}).

Sigma is the standard deviation of the Gaussian filter applied to the image. This filter is applied as a pre-processing step of our implementation as discussed in section \ref{subsec:implementation}. Through observation we have seen how dependent this parameter is on each image. In fact, in images from the qualitative dataset a much higher sigma value is required than in real images.

Finally, in section~\ref{subsubsec:numerical_issue}, we have seen the need for the $\epsilon$ this parameter. It is only specific to energies with Mixture Gaussian density functions. Through observation we have seen that this it is quite correlated with the sigma value, however this still remains to be tested and is left as future work (section~\ref{sec:conclusions}).

\subsection{Experiment 1: Independence from initialization.}
\label{subsubsec:experiment1}

In this first experiment we test the influence of adding a seed to the dependency on the initial contour with respect to the ground truth. To observe this relationship we will test the original Gaussian Energy with no seed against one with a seed. In this way, we can be sure that the results are not conditioned by other improvements.

\subsubsection{Experiment setup}

We use a simple synthetic gray-scale image shown in figure \ref{fig:synthetic_experiment1}. The object to segment is the black rectangular region whose values were generated by a Normal distribution of $\mu=50$, $\sigma=10$, while the exterior was generated with $\mu=150$, $\sigma=10$. We generated a set of circular curves with a diameter of 20 pixels, with centers located on the horizontal axis through the middle of the image and with 10 pixels of separation between neighboring centers.

\begin{figure}[h]
	\centering
	{\includegraphics[width=0.3\textwidth]{images/qualitative_tests/synthetic_experiment1.png}}
	\caption{Synthetic image used for experiment 1.}
	\label{fig:synthetic_experiment1}
\end{figure}
\subsubsection{Results}

In figure \ref{fig:seed_no_seed}, the first column represents the different initializations of the cage-contour configuration where, in each row, it is initialized closer to the solution. In the second and third columns, we have the resulting segmentation of the non-seeded and the seeded Gaussian energy respectively. 

As expected, the non-seeded energy does not converge to the solution when the initial configuration is not near to the solution. This stems from the fact that its statistics are re-calculated at every step and therefore it adopts the interior region as the description of the object it wants to segment. The peculiar shape adopted by the curve can be explained by the effect of the outer region component in the energy. As we have seen in section \ref{subsubsec:descriptive_analysis}, a region energy only influences the energy gradient if it contains significant changes in the image's gradient in points whose probability of being in that region is small. On the other hand, the outer region does meet this condition, thus driving the gradient towards the edge of the object. 

Conversely, in the case of the seeded energy, the cage converge in general. Again the outer region motivates the energy's gradient direction. Moreover, what is interesting in the seeded energy is the reluctance of the outermost points of the cage to move towards the object.  The parametrization using mean value coordinates adds a component of locality to the descent, as we described in \ref{subsubsec:descriptive_analysis}, which limits the influence of distant points on the gradient. This ``short-sightedness" of the cage already complicates the improvement of property \ref{property:energy3} of a good energy. Once the points are close enough to detect the gradient however, their path is blocked by the cage constraint which avoids self-intersection.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_initial_mask_68.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/no_seed/plot_final_mask_68.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_final_mask_68.png}\\[0.2em]
	
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_initial_mask_78.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/no_seed/plot_final_mask_78.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_final_mask_78.png}\\[0.2em]
	
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_initial_mask_88.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/no_seed/plot_final_mask_88.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_final_mask_88.png}\\[0.2em]
	
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_initial_mask_98.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/no_seed/plot_final_mask_98.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_final_mask_98.png}\\[0.2em]
	
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_initial_mask_108.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/no_seed/plot_final_mask_108.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_final_mask_108.png}\\[0.2em]
	
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_initial_mask_118.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/no_seed/plot_final_mask_118.png}\hspace{0.025\textwidth}%
	\includegraphics[width=0.2\textwidth]{images/qualitative_tests/experiment1/seed/plot_final_mask_118.png}\\[0.2em]
	\caption{From left to right, initialization, segmentation results of the Gaussian Energy with no seed and with seed. Parameters: 12 control points, ratio=1.05, sigma=0.	5, $\epsilon = e^{-200}$)}
	\label{fig:seed_no_seed}
	\end{figure}

\subsection{Experiment 2: Interpreting multiple regions.}
\label{subsubsec:experiment2}


In order to test the capability of a region to capture multiple values, we test the Mixture Gaussian energy. Again, we use only the gray-scale version of this energy to compare the improvement against the Gaussian energy (both with seeds), to see whether the improvement works and to see how far we can push it. 

\subsubsection{Experimental setup}
The image used (figure \ref{fig:synthetic_experiment2}) has three regions which from darkest to lightest have been generated with normal distribution with parameters ($\mu=150$, $\sigma=10$), ($\mu=100$, $\sigma=10$) and ($\mu=50$, $\sigma=10$) respectively. The object which we wish to segment is the second region (rectangle on the right) which has values between the other two regions. This should be problematic for the Gaussian Energy since it will most likely polarize the image's values. 

In this experiment we will evaluate the Mixture Gaussian Energy's capacity to overcome this problem as well as test its robustness when varying the object's values. The initial contour will be place in the middle of the image with its center between the two inner rectangles.

\begin{figure}[h!]
	\centering
	{\includegraphics[width=0.3\textwidth]{images/qualitative_tests/synthetic_experiment2.png}}
	\caption{Synthetic image used for experiment 3.}
	\label{fig:synthetic_experiment2}
\end{figure}

\subsubsection{Results}
In figure \ref{fig:mixture_robustness} we show the results of the normal and the mixture Gaussian energies in the second and third column respectively with different intensities of the object's values. In the plots on the first column, the distribution of the inner and outer seeds are plotted in blue and red respectively. These are shown over the probability of both seeds to show the magnitude of their contributions to the Energy function. As we can see the highest peak corresponds to the region with the highest intensity value while the smaller peaks correspond to the two rectangular regions in middle. It can be observed that in each new row, the increases of the intensity of the object's value's  is manifested on the graph as the distribution of the inner region's seed shifts towards higher intensity.

\noindent
\begin{figure}[h]
	\centering
	
	\includegraphics[width=0.37\textwidth]{images/qualitative_tests/experiment2/gmm/mixture_60_density_function.png}\hspace{0.0\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment2/gaussian/mixture_60.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment2/gmm/mixture_60.png}\\[-0.2em]
	
	\includegraphics[width=0.37\textwidth]{images/qualitative_tests/experiment2/gmm/mixture_80_density_function.png}\hspace{0.0\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment2/gaussian/mixture_80.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment2/gmm/mixture_80.png}\\[-0.2em]
	
	\includegraphics[width=0.37\textwidth]{images/qualitative_tests/experiment2/gmm/mixture_100_density_function.png}\hspace{0.0\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment2/gaussian/mixture_100.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment2/gmm/mixture_100.png}\\[-0.2em]
	
	
	\includegraphics[width=0.37\textwidth]{images/qualitative_tests/experiment2/gmm/mixture_120_density_function.png}\hspace{0.0\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment2/gaussian/mixture_120.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment2/gmm/mixture_120.png}\\[-0.2em]
	
	
	\includegraphics[width=0.37\textwidth]{images/qualitative_tests/experiment2/gmm/mixture_140_density_function.png}\hspace{0.0\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment2/gaussian/mixture_140.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment2/gmm/mixture_140.png}\\[-0.2em]
	
	\caption{Experimental validation of the capacity of the Mixture Gaussian energy (left column) to capture a region with values between the background's values. Parameters: 12 control points, ratio=1.05, sigma=1.25, $\epsilon = e^{-200}$)}
	\label{fig:mixture_robustness}
\end{figure}


The results of the energy with one Normal distribution immediately confirm our hypothesis of its polarizing effect. In the first three rows, it considers both squares as the inner region despite one of them being in the outer. The mixture Gaussian on the other hand is successful in segmenting the inner region yet it behaves badly when it's values are similar to one of the outer region's components has the same intensity, because both regions' gradient claim this region for themselves.


\subsection{Experiment 3: Invariance to illumination}
\label{subsubsec:experiment3}

The purpose of this experiment is to see how the Hue Energy can outperform in some cases the Multivariate Gaussian Energy (the same as the Gaussian energy but in RGB) in particular with changes in intensity.
\begin{figure}[H]
	\centering
	{\includegraphics[width=0.3\textwidth]{images/qualitative_tests/color_image_original.png}}
	\caption{Synthetic image used for experiment 2.}
	\label{fig:synthetic_experiment3}
\end{figure}

\subsubsection{Experimental setup}
In this experiment, robustness to change of illumination is tested with the Multivariate Gaussian Energy and the Hue Mean Energy. The image if figure \ref{fig:synthetic_experiment3} will be used. The interior and the exterior are generated by Gaussians with parameters $\mu=(0,145,110)$ and covariance matrix $covars=Id*10$, and  $\mu=(0,110,145)$ and $covars=Id*10$ respectively. In order to test for changes of illumination we  linearly decreased the \textit{luminance} (amount of light hitting the sensor from a surface)\cite{conf/cvpr/Yu09},  using Adobe Photoshop. The initial curve is always located inside the object.

\subsubsection{Results}
In figure \ref{fig:ilumination_variation}, the left column represents the segmentation results of the Hue Mean model whereas the right column represents the Multivariate Gaussian Energy. As we can see, as the image gets darker, the Hue Mean Energy systematically outperforms the other. This is due to the fact that Hue is an intrinsic property of an object, and its transformation perfectly conserves color since the value or intensity is kept in the V/I channel in HSV/HSI.

\noindent
\begin{figure}[h!]
	\centering
	
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment3/hue/plot_im_dark_4_8.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment3/gmm/plot_im_dark_4_8.png}\\[0.em]
	
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment3/hue/plot_im_dark_3_8.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment3/gmm/plot_im_dark_3_8.png}\\[0.em]
	
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment3/hue/plot_im_dark_5_8.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment3/gmm/plot_im_dark_5_8.png}\\[0.em]
	
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment3/hue/plot_im_dark_6_8.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment3/gmm/plot_im_dark_6_8.png}\\[0.em]
	
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment3/hue/plot_im_dark_7_8.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/qualitative_tests/experiment3/gmm/plot_im_dark_7_8.png}\\[-0.5em]
	
	\caption{Segmentation results of the mean Hue energy (left column) and of the Multivariate Gaussian Energy (right colum) with different illuminations. Parameters: 12 control points, ratio=1.05, sigma=0.25, $\epsilon = e^{-200}$)}
	\label{fig:ilumination_variation}
\end{figure}

To a certain extent, these results exceed our expectation. In the case of the last image, also successfully segmented by the mean Hue energy, the object is barely visible. Although the modification was done digitally, we can conclude that in a setting with either very high or very low luminosity, if a slightest hint of color is successfully captured, this method would be able even to surpass human segmentation. This confirms the need for experimenting with energies in different color spaces.

\section{Quantitative results}
\label{subsec:quantitative_experiment}
We have carried out two different quantitative experiments. In the first one, we compare the different energies in CAC to evaluate our improvements and, in the second, we compare our methods to other existing ones to see where ours stand. We have evaluated these on both real image datasets described in section \ref{subsec:dataset} using the S\o rensen-Dice coefficient. 

\subsection{Experiment 4: Comparison with different energies in CAC}

The goal of this experiment is to quantify the improvements of our energies with respect to the previous ones defined in \cite{ipcac2015}. To do so, we have evaluated different Energies that contain gradual improvements. 

\subsubsection{Experimental design}

In table \ref{table:energy_description}, we see a categorical description of each energy we have implemented. The category \textit{Seed} refers to whether or not the energy's description of a region is given by a seed from the foreground or background, as opposed to learning it in each iteration. The \textit{color space} refers to the type of image it accepts, be it gray-scale, RGB or Hue. The \textit{Multi-component} category refers to the energy's capability of learning more than one distribution per region.

\begin{table}[h!]
	\centering
	\begin{tabular}{|l|c|c|c|}
		\hline
		\textbf{Energies}  & \textbf{Seed} &\textbf{Color space} & \textbf{Multi-comp}   \\ \hline
		Mean  & No & gray-scale & No \\ \hline
		Gaussian & No & gray-scale  & No \\ \hline
		Seeded Gaussan  & Yes & gray-scale & No\\ \hline
		Mixture Gaussan  & Yes & gray-scale & Yes\\ \hline
		Multivariate Gaussan & Yes & RGB & No \\ \hline
		Multivariat Mixture Gaussan & Yes & RGB & Yes \\ \hline
		Hue Mean & Yes & Hue & No \\ \hline
	\end{tabular}
	\caption{Different energies evaluated}
	\label{table:energy_description}
\end{table}

In order to compare each method, we have run 3-fold cross validation (see sectio~ \ref{subsec:model_validation}) over four different parameters whose values can be seen in table \ref{table:parameters}. 

\subsubsection{Results}

In table \ref{table:cac_results}, we see the mean S\o rensen-Dice coefficient (S-D) expressed in percentage and its standard deviation (std.) with each method.
\begin{table}[h!]
	\centering
	\begin{tabular}{lllll}
		\toprule
		\textbf{Energy}& \multicolumn{2}{c}{\textbf{AlpertGBB07}} & \multicolumn{2}{c}{\textbf{BSDS300}} \\
		& \textbf{S-D ( \%)} & \textbf{Std. dev.}  & \textbf{S-D ( \%)} & \textbf{Std. dev.}  \\ \midrule
		\textbf{Multivariate Mixture Gaussian} & \textbf{77.88} & 1.3    &     \textbf{55.58}  &  2.89     \\
		\textbf{Multivariate Gaussian} & 72.23 & 3.4 & 51.06 & 6.3 \\
		%\textbf{Multivariate Gaussian} & - & - & - & - \\
		\textbf{Mixture Gaussian} &  65.15 &   2.3    &     46.16 &  5.70 \\
		%\textbf{Seeded Gaussian} &  - & - & - & - \\
		\textbf{Gaussian} &  57.13 &   3.38    &    44.90  &  5.06     \\
		\textbf{Mean} & 57.11 & 2.87 & 37.85  & 4.34 \\
		\textbf{Hue Mean} & 56.97 & 5.78 & 41.43  & 4.02 \\
		\vspace{0.5em}
	\end{tabular}
	\vspace{-0.4cm}
	\caption{Comparison of the different CAC Energies.}
	\label{table:cac_results}
\end{table}


Immediately, we can see how the S\o rensen-Dice coefficient in both datasets is correlated with the number of improvements of each method. The best method is the one with the most complex energy: the Multivariate Mixture Gaussian Energy. The worst however seems to be the Hue mean energy.

It is interesting to see that when comparing the improvements defined in table \ref{table:energy_description}, we have that the most impactful improvement is the extension to the RGB color space. This improvement of about 20 points in both the AlperGBB07 and the BSDS300 database unequivocally confirms the positive impact of our main contributions. The energies with multiple components also provide an enhancement in performance but not to such a great extent. This could be a consequence of the numerical problem described in~\ref{subsubsec:numerical_issue}. It remains to be studied for future work if other alternative solutions exist apart from our $\varepsilon$. Moreover, the introduction of a seed also seems to have outperformed the non-seeded energies.


\begin{table}[h!]
	\centering
	
	\begin{tabular}{lll}
		\toprule
		\textbf{Method}& & \\
		& \textbf{Mean time ( sec.)} & \textbf{Std.}   \\ \midrule
		\textbf{Multivariate Mixture Gaussian} & 38.72 & 15.74 \\
		\textbf{Multivariate Gaussian} & 32.22 & 17.03\\ 
		\textbf{Mixture Gaussian} & 24.18 & 14.20 \\ 
		\textbf{Seeded Gaussian} & 21.16 & 15.53  \\ 
		\textbf{Gaussian} & 22.78 & 11.96 \\
		\textbf{Mean} & 21.17 & 10.02 \\
		\textbf{Mean Hue} & 25.17 & 14.06\\
		\vspace{0.5em}
	\end{tabular}
	\caption{Comparison of computational time of the segmentation of CAC with different Energies for  300x225 images.}
	\label{table:computational_time}
\end{table}

In terms of computational results, we have seen in table~\ref{table:computational_time} that the CAC in general is a very slow image segmentation method. Although the introduction of a seed decreases the computational time by avoiding the computation of the region's description in every iteration, we see that in the Multivariate Mixture Gaussian energy, the Expectation-Maximization is extremely slow.

\subsection{Experiment 5: Comparison with other methods}

Our motivation in this experiment is to place our contribution's results into context with respect to other similar methods in the literature. In order to do this we will compare our methods with other existing ones to see how well they perform and to get an idea of how much of a leap over the previous CAC Energies we have improved.


\subsubsection{Experimental design}

We have taken three active contour methods and used their implementation in Creaseg~\cite{5652991}, a free software for the evaluation of image segmentation techniques. These methods are: the Geodesic Active Contours presented by Vicent Caselles~\cite{Caselles1993}, the Chan\&Vese~\cite{ChanVese}, and the Shi~\cite{4480128}.

The Method by Caselles, is a level set based on object boundary detection energy. Like all level-set methods the contours can contract, expand, merge and split. In this particular this method adds restriction on the curve based on geodesic (minimal) distances. It has proven to be robust in boundary detection with badly defined gradients as well.

The Chan\&Vese provide a stable method which allows for detection with object whose boundaries are not well necessarily defined by a gradient. The energy used, is the mean energy in \eqref{eq:level_set_mean} on which the CAC's was inspired.

The Shi method is a level set with region-based energy that can be implemented in real time. That is, it can accomplish a good result in fewer iterations.

We have decided to use the Chan\&Vese, the Caselles and the Shi methods because in the original paper of Creaseg~\cite{5652991}, these are reported to have the best results.

Like in~\cite{5652991}, we have used the default parameters given by each author to compare with our algorithms. We on the other hand have performed a 3-fold Cross validation on the parameters as described in the previous experiment. We have decided to compare them to the Gaussian Energy, and the Multivariate Mixture Gaussian Energy (each described in table \ref{table:energy_description}).

\subsubsection{Results}

In table \ref{table:results}, we see the mean S\o rensen-Dice coefficient and its standard deviation with each method. Our Multivariate Mixture Gaussian Energy scored best in the AlpertGBB07 dataset and third best in the BSDS300 dataset. These positive results were expected given that it uses RGB information while the methods from Creaseg use gray-scale images. For this reason we have also decided to show the Mixture Gaussian energy which is the equivalent energy in this color space. In this case, the Shi and the Caselles method were outperformed in The AlpertGBB07.

\begin{table}[h!]
	\centering
	\begin{tabular}{lllll}
		\toprule
		\textbf{Method} & \multicolumn{2}{c}{\textbf{AlpertGBB07}} & \multicolumn{2}{c}{\textbf{BSDS300}} \\
		& \textbf{S-D. ( \%)} & \textbf{Std.}  & \textbf{S-D ( \%)} & \textbf{Std.}  \\ \midrule
		\textbf{ChanVese} & 70.71 & 14.14 &  64.45  &  14.59 \\
		\textbf{Shi} & 61.34 & 20.23 &  52.15  & 21.50\\
		\textbf{Caselles} & 58.68 & 17.02 &  \textbf{63.15}  &  13.76 \\
		\textbf{CAC: Multivariate Mixture Gaussian} & \textbf{77.88}& 1.3    &     55.58  &  2.89     \\
		\textbf{CAC: Mixture Gaussian} &  65.15 &   2.3    &  44.90  &  5.06  \\
		\textbf{CAC: Hue Mean} & 56.97 & 5.78 & 41.43  & 4.02 \\
		\vspace{0.5em}
	\end{tabular}
	\caption{Comparison of the best segmentation Energies in CAC with other existing related methods.}
	\label{table:results}
\end{table}

\begin{table}[h!]
	\centering
	\begin{tabular}{lll}
		\toprule
		\textbf{Method}& & \\
		& \textbf{Mean time ( sec.)} & \textbf{Std.}   \\ \midrule
		\textbf{Caselles} & 3.47 & 0.69 \\ % alpert 1.972682927 0.56172068
		\textbf{ChanVese} & 3.50 & 0.24 \\ %alpert 2.061219512 0.571341383
		\textbf{Shi} & 114.52 & 113.84  \\ %alpert 56.02243902 67.87887185
		\textbf{CAC: Multivariate Mixture Gaussian} & 38.72 & 15.74 \\
		\textbf{CAC: Mixture Gaussian} & 24.18 & 14.20 \\ 
		\textbf{CAC: Gaussian} & 22.78 & 11.96 \\
		%\textbf{Mean} & 21.17 & 10.02 \\
		%\textbf{Mean Hue} & 25.17 & 14.06\\
		\vspace{0.5em}
	\end{tabular}
	\caption{Comparison of computational time  in 300x225  images of the best CAC energies with other existing related methods in 300x225  images.}
	\label{table:computational_time_other}
\end{table}

In terms of computational time, we see that the Caselles and the Chan\&Vese are extremely fast while the Shi, that is supposed to be fast, took the longest because of the default number of iterations in the Creaseg Implementation. 

\section{Specific examples}
\noindent

In this section, we are going to discuss some of the good and bad results we obtained using specific example images and visual evaluation. These results were obtained by the Multivariate Mixture Gaussian energy's best parameter (Number of control points=20, ratio=1.1, sigma=0.25, $\epsilon = e^{-200}$)

In figures \ref{fig:cut_tree} and \ref{fig:purse}, we see two images which were exclusively successful using the Multivariate Gaussian Mixture Energies. In the image of the purse, the spotted texture and the two background colors are perfectly captured using this energy, where as in the image of the log, the different textures are also reasonably well interpreted.

\begin{figure}[h!]
	\centering
	\begin{minipage}{0.45\textwidth}
		\centering
		{\includegraphics[width=0.8\textwidth]{images/seg_im/plot_result_img_2592_f.png}} % first figure itself
		\caption{Segmentation result with Multivariate Mixture Gaussian Energy} \label{fig:cut_tree}
	\end{minipage}\hfill
	\begin{minipage}{0.5\textwidth}
		\centering
		{\includegraphics[width=0.8\textwidth]{images/seg_im/plot_result_dsc01239_d.png}}
		\caption{Segmentation result with Multivariate Mixture Gaussian Energy.}\label{fig:purse}
	\end{minipage}
	\centering
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{minipage}{0.45\textwidth}
		\centering
		{\includegraphics[width=0.8\textwidth]{images/seg_im/plot_result_b_outside_guggenheim_walls.png}} % first figure itself
		\caption{Segmentation result with Multivariate Mixture Gaussian Energy} \label{fig:guggenheim}
	\end{minipage}\hfill
	\begin{minipage}{0.5\textwidth}
		\centering
		{\includegraphics[width=0.8\textwidth]{images/seg_im/plot_result_imagen_072__1_.png}}
		\caption{Segmentation result with Multivariate Mixture Gaussian Energy.}\label{fig:akbar}
	\end{minipage}
	\centering
\end{figure}

The image of the broken tree, however, displays an irregular behavior at the bottom ot the image. We have observed that this phenomena is common among images whose objects are cut by the margin of the image. Figures ~\ref{fig:guggenheim} and \ref{fig:akbar} are also examples of this. Following the discussion in section ~\ref{subsec:analysis_mmge}, we have mentioned that a region only contributes to the gradient if it has pixels whose values do not belong to the probability distribution of the region. In the case of these images then, the inner region has virtually no effect on the gradient because it resides inside the object. The external energy, does not respond either because it has no external component which belongs to the outer region and thus does not pull the vertex outside of the image because there is no change in gradient which motivates it into doing so.

The images in figure~\ref{fig:cac_results} show some positive results of CAC. As we can see, CAC are not meant for high precision segmentation but rather they provide a smooth general contour of the image. 

\begin{figure}[h!]
	\centering
	
	\includegraphics[width=0.27\textwidth]{images/seg_im/plot_result_b_hot_air_balloons_05.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/seg_im/plot_result_b_img_3803.png}\\[0.em]
	
	\includegraphics[width=0.27\textwidth]{images/seg_im/plot_result_b14pavel013.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/seg_im/plot_result_img_4730_modif.png}\\[0.em]
	
	\includegraphics[width=0.27\textwidth]{images/seg_im/plot_result_dscn0756.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/seg_im/plot_result_dscn1908.png}\\[0.em]
	
	\includegraphics[width=0.27\textwidth]{images/seg_im/plot_result_pict2272.png}\hspace{0.005\textwidth}%
	\includegraphics[width=0.27\textwidth]{images/seg_im/plot_result_dscf3772.png}\\[-0.5em]
	
	\caption{Positively segmented images using the Multivariate Mixture Gaussian Energy.}
	\label{fig:cac_results}
\end{figure}




