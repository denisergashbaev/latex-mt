\newpage
\chapter{Methodology}
\label{sec:proposal}
\noindent
This master thesis proposes an application of deep CNNs to a task of counting objects in the image. The provided system is to address all the aforestated issues which object detection and counting applications have encountered. Such as:
\begin{itemize}
	\item Being prone to error in noisy or crowded scenes with a noticeable occlusion. 
	\item Establishing the viability of a privacy-preserving approach. 
	\item Painstaking hand-crafted image features which are highly dependent on the object class. 
	\item Scrupulous data annotation for manifold data. 
\end{itemize} 
In addition, the deficit in the state-of-the-art \cite{segui2015learning} which would be the applicability and performance of a system trained with synthetic dataset in real world counting problem\cite{chan2008privacy}. The novelty of our approach compare to the state of the art is that we hypothesize that features learned by training a counting deep CNN on a synthetic dataset, are representative enough to count the number of object of interest in a real dataset. We tackle this task as a regression problem. 
To the best of our knowledge, the proposed work would be the first one in which a counting system trained with synthetic images is able to be incorporated in real-world similar counting problems.

Henceforth, in the rest of this chapter, we justify our methodology along with a comparison to state-of-the-art from different aspects such as method selection, architecture, dataset and its application.   


%This master thesis proposes an application of deep convolutional neural networks to a task of counting objects in the image. The novelty of our approach compare to the state of the art is that we hypothesize that features learned by training a counting deep CNN on a synthetic dataset, are representative enough to count the number of object of interest in a real dataset. This approach has been taken to immensely reduce feature detection and data annotation efforts in the state of the art. Furthermore, due to the synthetic nature state of the art\cite{segui2015learning}, we would to examine the performance of such systems on a larger scale real world counting problem. 

%Hence, to verify our hypothesis and resolve the deficits of the state-of-the-art, first we scale up  \citealt*{segui2015learning}' work along with a different architecture to observe if we attain promising results, and then we compare the performance of our model with the results \citeauthor{chan2008privacy} achieved on real dataset\cite{chan2008privacy}.  
%To the best of our knowledge, the proposed work would be the first one in which a counting system trained with synthetic images is able to be incorporated in real-world similar counting problems.

%Henceforth, in the course of this chapter, we explain different components of our system more in details

\section{Method selection}

For a long time in Computer Vision, there has been a prevailing paradigm in which we have a set of feature descriptors such SIFT \cite{lowe1999object}, HOG\cite{dalal2005histograms}, SURF\cite{bay2006surf} and many more to that can be extracted from the image with possible higher level feature building following by a classifier like Support Vector Machines (SVM) \cite{vapnik1964note, boser1992training}. In fact, for the most part, these features are not learned, but hand-crafted by some vision experts. However, they do have indeed descent performance. For instance, in one of the most successful works in object detection, in \cite{felzenszwalb2010object} the author essentially introduces a linear classifier on top of HOG features, or regarding classification approaches that work quite well, \citeauthor{yu2010object} use all manners of features (HOG, SIFT, Color SIFT, etc) extracted from the images and consequently obtain impressive results. 

\indent The analysis of these works develop this question that in order to improve the vision systems accuracy, in which part of the system should we focus on? Should we try to enhance classifiers, should we increase the amount of data or we had better provide finer features? \citeauthor*{parikh2010role} in \cite{parikh2010role} analyze the role of features by taking some of the quite successful past deformable models\cite{albrecht2015deformable}, and replace some components of them with humans. they present identical learning tasks \textit{i.e.} the same feature representation and the same training data, to machines and humans which allows drawing a comparison between the two. The author concludes that features are the main factor contributing to superior human performance. Furthermore, in \cite{gehler2009feature}, compared 39 different learning kernels with different combination features to see which kernel outperforms the rest and how it should be weighted. Although they got a big jump over the existing methods, the analysis of their results shows that the gain they obtained from the learning operators is not as dramatic as the improvement they achieved from the features itself. 

\indent Therefore, since the features are doing most of the works in these algorithms, if we improve those, we can attain better algorithms. The difficulty of feature improvement and high cost of numerous features computation on each image brought us into the application of deep learning in order to learn the features themselves rather than hand-crafting them. 

In deep learning techniques, we essentially have a hierarchy of feature extractors which attempts to model high-level abstractions in data\cite{deng2014deep, bengio2009learning, bengio2013representation, arel2010deep, schmidhuber2015deep}










% why cnn are good for feature detection. remarkable results of this method. 
% the future and the existence of big data and fast gpu computation 
% great performance on regression and classification 
\section{Architecture}
% convolutional layer and fully connected layers
% why not too deep and not too shallow 
% why stochastic gradient descent and other methods 
\section{Datasets} 


\section{Method Application}


%\begin{equation} \label{eq:curvilinear_energy}
%\begin{split}
%I \colon & \mathbb{R}^{D} \phantomarrow{AAAA} {}\mathbb{S}^1\times\mathbb{R}^2\\
%& \phantomarrow{AAA}{p} I(p) =(h,s,i)
%\end{split}
%end{equation}

%\begin{figure}[h!]
	%\centering
	%\begin{minipage}{0.45\textwidth}
		%\centering
		%{\includegraphics[width=0.8\textwidth]{images/image_in_question_modified.png}} % first figure itself
		%\caption{First step of the iteration in the segmentation. The initial cage in blue, the contour in white and the next cage in green with ten times the learning rate of step 1.} \label{fig:image_in_question}
	%\end{minipage}\hfill
	%\begin{minipage}{0.5\textwidth}
		%\centering
		%{\includegraphics[width=1.\textwidth]{images/gradient_plot_edit.png}}
		%\caption{Contribution of the points in a slice of image~\ref{fig:image_in_question} on the direction of the gradient with respect to $v_i$ of the x axis.}\label{fig:plot_in_question}
	%\end{minipage}
	%\centering
